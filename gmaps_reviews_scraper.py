"""
Google Maps Reviews Scraper
Extrae rese√±as de Google Maps para identificar pain points de las cl√≠nicas
"""

import time
import re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import json


class GoogleMapsReviewsScraper:
    def __init__(self, headless=False):
        self.headless = headless
        self.driver = None
        self.reviews = []

    def setup_driver(self):
        """Configura el navegador Chrome con opciones anti-detecci√≥n"""
        chrome_options = Options()

        if self.headless:
            chrome_options.add_argument('--headless=new')

        # Opciones para evitar detecci√≥n
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_argument('user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)

        try:
            # Instalar chromedriver autom√°ticamente
            driver_path = ChromeDriverManager().install()

            # Fix para Mac ARM - el driver est√° en un subdirectorio
            import os
            import stat
            if 'THIRD_PARTY' in driver_path or not driver_path.endswith('chromedriver'):
                # Buscar el chromedriver real
                driver_dir = os.path.dirname(driver_path)
                actual_driver = os.path.join(driver_dir, 'chromedriver')
                if os.path.exists(actual_driver):
                    driver_path = actual_driver

            # Asegurar permisos de ejecuci√≥n
            if os.path.exists(driver_path):
                os.chmod(driver_path, stat.S_IRWXU | stat.S_IRGRP | stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)

            service = Service(driver_path)
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            return True
        except Exception as e:
            print(f"‚ùå Error al iniciar Chrome: {str(e)}")
            print("\nüí° Verifica que Chrome est√© instalado")
            return False

    def extract_reviews_from_place(self, place_name, place_url=None, max_reviews=50, city=None):
        """
        Extrae rese√±as de un lugar espec√≠fico

        Args:
            place_name: Nombre del lugar
            place_url: URL directa del lugar en Google Maps (opcional)
            max_reviews: N√∫mero m√°ximo de rese√±as a extraer
            city: Ciudad del lugar (opcional, mejora precisi√≥n de b√∫squeda)
        """
        print(f"\n{'='*70}")
        print(f"üîç Extrayendo rese√±as de: {place_name}")
        print(f"{'='*70}")

        if not self.driver:
            if not self.setup_driver():
                return []

        try:
            # Si no hay URL, buscar el lugar
            if not place_url:
                # Incluir ciudad en la b√∫squeda para mejor precisi√≥n
                search_query = f"{place_name}"
                if city:
                    search_query += f" {city}"
                search_query += " Google Maps"
                print(f"üîç Buscando: {search_query}")
                self.driver.get(f"https://www.google.com/maps/search/{search_query}")
                time.sleep(3)

                # Hacer clic en el primer resultado
                try:
                    first_result = WebDriverWait(self.driver, 10).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, "a[href*='/maps/place/']"))
                    )
                    first_result.click()
                    time.sleep(3)
                except:
                    print("‚ö†Ô∏è  No se encontr√≥ el lugar")
                    return []
            else:
                print(f"üåê Navegando a URL directa...")
                self.driver.get(place_url)
                time.sleep(3)

            # Hacer clic en el bot√≥n de rese√±as
            try:
                # Buscar el bot√≥n que muestra el n√∫mero de rese√±as
                reviews_button = WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "button[aria-label*='rese√±as'], button[aria-label*='reviews']"))
                )
                reviews_count_text = reviews_button.get_attribute('aria-label')
                print(f"üìä Rese√±as encontradas: {reviews_count_text}")

                # Click en el bot√≥n
                self.driver.execute_script("arguments[0].click();", reviews_button)
                time.sleep(2)

            except Exception as e:
                print(f"‚ö†Ô∏è  No se pudo hacer clic en rese√±as: {str(e)}")
                print("üîÑ Intentando m√©todo alternativo...")

            # Scroll para cargar m√°s rese√±as
            print(f"üìú Cargando rese√±as...")
            reviews_loaded = self._scroll_reviews(max_reviews)
            print(f"‚úÖ {reviews_loaded} rese√±as cargadas")

            # Extraer datos de las rese√±as
            reviews_data = self._extract_reviews_data(place_name, max_reviews)

            print(f"‚úÖ {len(reviews_data)} rese√±as extra√≠das exitosamente")

            return reviews_data

        except Exception as e:
            print(f"‚ùå Error extrayendo rese√±as: {str(e)}")
            return []

    def _scroll_reviews(self, max_reviews):
        """Hace scroll en el panel de rese√±as para cargar m√°s"""
        try:
            # Encontrar el contenedor scrollable de rese√±as
            scrollable_div = self.driver.find_element(By.CSS_SELECTOR, "div[role='main']")

            last_height = 0
            attempts = 0
            max_attempts = 20  # N√∫mero m√°ximo de scrolls

            while attempts < max_attempts:
                # Scroll down
                self.driver.execute_script(
                    'arguments[0].scrollTo(0, arguments[0].scrollHeight);',
                    scrollable_div
                )
                time.sleep(1.5)

                # Verificar si hay m√°s rese√±as
                current_reviews = len(self.driver.find_elements(By.CSS_SELECTOR, "div[data-review-id]"))

                if current_reviews >= max_reviews:
                    print(f"  ‚úì Alcanzado l√≠mite de {max_reviews} rese√±as")
                    break

                # Verificar si llegamos al final
                new_height = self.driver.execute_script(
                    "return arguments[0].scrollHeight",
                    scrollable_div
                )

                if new_height == last_height:
                    print(f"  ‚úì Fin de rese√±as alcanzado")
                    break

                last_height = new_height
                attempts += 1

                if attempts % 5 == 0:
                    print(f"  Scroll {attempts}/{max_attempts} - {current_reviews} rese√±as cargadas...")

            return current_reviews

        except Exception as e:
            print(f"‚ö†Ô∏è  Error en scroll: {str(e)}")
            return 0

    def _extract_reviews_data(self, place_name, max_reviews):
        """Extrae datos de todas las rese√±as visibles"""
        reviews = []

        try:
            # Expandir todas las rese√±as que tengan "M√°s" o "More"
            try:
                more_buttons = self.driver.find_elements(By.CSS_SELECTOR, "button[aria-label*='M√°s'], button[aria-label*='More']")
                print(f"  üìñ Expandiendo {len(more_buttons)} rese√±as...")
                for button in more_buttons[:max_reviews]:
                    try:
                        self.driver.execute_script("arguments[0].click();", button)
                        time.sleep(0.3)
                    except:
                        pass
            except:
                pass

            # Extraer cada rese√±a
            review_elements = self.driver.find_elements(By.CSS_SELECTOR, "div[data-review-id]")

            print(f"  üìù Extrayendo datos de {min(len(review_elements), max_reviews)} rese√±as...")

            for idx, review_elem in enumerate(review_elements[:max_reviews], 1):
                try:
                    # Nombre del reviewer
                    try:
                        reviewer = review_elem.find_element(By.CSS_SELECTOR, "div.d4r55").text
                    except:
                        reviewer = "An√≥nimo"

                    # Rating (estrellas)
                    try:
                        rating_elem = review_elem.find_element(By.CSS_SELECTOR, "span[role='img']")
                        rating_text = rating_elem.get_attribute('aria-label')
                        rating = float(re.search(r'(\d+)', rating_text).group(1))
                    except:
                        rating = None

                    # Fecha
                    try:
                        date = review_elem.find_element(By.CSS_SELECTOR, "span.rsqaWe").text
                    except:
                        date = "Desconocida"

                    # Texto de la rese√±a
                    try:
                        review_text = review_elem.find_element(By.CSS_SELECTOR, "span.wiI7pd").text
                    except:
                        review_text = ""

                    # Respuesta del propietario (si existe)
                    try:
                        owner_response = review_elem.find_element(By.CSS_SELECTOR, "div.wiI7pd").text
                    except:
                        owner_response = ""

                    reviews.append({
                        'place_name': place_name,
                        'reviewer': reviewer,
                        'rating': rating,
                        'date': date,
                        'review_text': review_text,
                        'owner_response': owner_response,
                        'extracted_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    })

                    if idx % 10 == 0:
                        print(f"    ‚úì {idx}/{min(len(review_elements), max_reviews)} rese√±as procesadas...")

                except Exception as e:
                    print(f"    ‚ö†Ô∏è  Error en rese√±a {idx}: {str(e)}")
                    continue

            return reviews

        except Exception as e:
            print(f"‚ùå Error extrayendo datos de rese√±as: {str(e)}")
            return reviews

    def analyze_pain_points(self, reviews):
        """
        Analiza las rese√±as para identificar pain points comunes
        que pueden resolverse con un chatbot
        """
        print(f"\n{'='*70}")
        print("üîç AN√ÅLISIS DE PAIN POINTS")
        print(f"{'='*70}")

        pain_points = {
            'atencion_telefonica': [],
            'demora_respuesta': [],
            'dificultad_agendar': [],
            'horarios_limitados': [],
            'falta_seguimiento': [],
            'informacion_precios': [],
            'otros': []
        }

        # Keywords para detectar pain points
        keywords = {
            'atencion_telefonica': [
                'no contestan', 'no responden el tel√©fono', 'llamo y no contestan',
                'nunca contestan', 'tel√©fono ocupado', 'no atienden llamadas',
                'imposible comunicarse', 'no cogen el tel√©fono'
            ],
            'demora_respuesta': [
                'demoran en responder', 'tardan mucho', 'respuesta lenta',
                'muy demorados', 'esper√© mucho', 'sin respuesta', 'no responden whatsapp',
                'demora whatsapp', 'tardan en contestar'
            ],
            'dificultad_agendar': [
                'dif√≠cil agendar', 'citas llenas', 'no hay citas', 'sin disponibilidad',
                'imposible conseguir cita', 'muy dif√≠cil sacar cita', 'agenda llena'
            ],
            'horarios_limitados': [
                'horarios cortos', 'cierran temprano', 'solo atienden', 'horario limitado',
                'no atienden fines de semana', 'horario reducido'
            ],
            'falta_seguimiento': [
                'no me llamaron', 'sin seguimiento', 'olvidan las citas',
                'no me recordaron', 'falta recordatorio', 'sin confirmaci√≥n'
            ],
            'informacion_precios': [
                'no informan precios', 'sin precios', 'no dicen cu√°nto cuesta',
                'precios ocultos', 'no hay informaci√≥n de costos'
            ]
        }

        # Analizar cada rese√±a
        for review in reviews:
            text = review['review_text'].lower()
            rating = review.get('rating', 5)

            # Solo analizar rese√±as negativas (1-3 estrellas)
            if rating and rating <= 3:
                matched = False
                for category, terms in keywords.items():
                    if any(term in text for term in terms):
                        pain_points[category].append({
                            'reviewer': review['reviewer'],
                            'rating': rating,
                            'text': review['review_text'][:200],  # Primeros 200 chars
                            'date': review['date']
                        })
                        matched = True

                if not matched and len(text) > 20:
                    pain_points['otros'].append({
                        'reviewer': review['reviewer'],
                        'rating': rating,
                        'text': review['review_text'][:200],
                        'date': review['date']
                    })

        # Mostrar resumen
        print(f"\nüìä Resumen de Pain Points:\n")
        total_issues = 0
        for category, issues in pain_points.items():
            if issues:
                count = len(issues)
                total_issues += count
                category_name = category.replace('_', ' ').title()
                print(f"  ‚Ä¢ {category_name}: {count} menciones")

        print(f"\n  Total de quejas identificadas: {total_issues}")

        return pain_points

    def generate_pitch_suggestions(self, pain_points):
        """Genera sugerencias de pitch basadas en los pain points"""
        suggestions = []

        pitch_templates = {
            'atencion_telefonica': (
                "Vi que algunos pacientes mencionan dificultad para comunicarse por tel√©fono. "
                "Nuestro chatbot puede responder autom√°ticamente el 80% de consultas b√°sicas 24/7, "
                "liberando su l√≠nea telef√≥nica solo para casos que realmente necesiten atenci√≥n humana."
            ),
            'demora_respuesta': (
                "Not√© quejas sobre demoras en responder WhatsApp. "
                "El chatbot responde instant√°neamente consultas frecuentes sobre servicios, precios y disponibilidad, "
                "mientras su equipo se enfoca en casos m√°s complejos."
            ),
            'dificultad_agendar': (
                "Veo que hay quejas sobre dificultad para conseguir citas. "
                "Nuestro sistema permite agendar citas 24/7 autom√°ticamente, "
                "mostrando disponibilidad en tiempo real y enviando confirmaciones."
            ),
            'horarios_limitados': (
                "Algunos pacientes mencionan horarios limitados de atenci√≥n. "
                "El chatbot funciona 24/7, permitiendo que los pacientes agenden citas, "
                "consulten informaci√≥n y dejen mensajes incluso fuera de su horario."
            ),
            'falta_seguimiento': (
                "Not√© menciones sobre falta de recordatorios. "
                "El chatbot puede enviar recordatorios autom√°ticos de citas, "
                "confirmaciones y seguimientos post-tratamiento, reduciendo ausencias."
            ),
            'informacion_precios': (
                "Algunos pacientes preguntan sobre precios. "
                "El chatbot puede compartir listas de precios, paquetes y promociones "
                "autom√°ticamente, convirtiendo consultas en citas agendadas."
            )
        }

        for category, issues in pain_points.items():
            if issues and category in pitch_templates:
                suggestions.append({
                    'pain_point': category.replace('_', ' ').title(),
                    'mentions': len(issues),
                    'suggested_pitch': pitch_templates[category]
                })

        return suggestions

    def save_to_excel(self, reviews, filename):
        """Guarda las rese√±as en un archivo Excel"""
        df = pd.DataFrame(reviews)
        df.to_excel(filename, index=False)
        print(f"\nüíæ Rese√±as guardadas en: {filename}")

    def save_to_json(self, data, filename):
        """Guarda datos en formato JSON"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"üíæ Datos guardados en: {filename}")

    def close(self):
        """Cierra el navegador"""
        if self.driver:
            self.driver.quit()


# Funci√≥n de ayuda para procesar m√∫ltiples lugares
def extract_reviews_from_leads_file(leads_file, max_reviews_per_place=30, max_places=10):
    """
    Extrae rese√±as de m√∫ltiples lugares desde un archivo CSV/Excel de leads

    Args:
        leads_file: Ruta al archivo de leads (CSV o Excel)
        max_reviews_per_place: M√°ximo de rese√±as por lugar
        max_places: M√°ximo de lugares a procesar
    """
    print(f"üìÇ Cargando leads desde: {leads_file}")

    # Cargar el archivo
    if leads_file.endswith('.csv'):
        df = pd.read_csv(leads_file)
    else:
        df = pd.read_excel(leads_file)

    print(f"‚úÖ {len(df)} leads cargados")

    # Filtrar solo los que tienen buen rating pero podr√≠an mejorar (4.0-4.5)
    df_filtered = df[(df['rating'] >= 4.0) & (df['rating'] <= 4.5)].head(max_places)

    print(f"üéØ Procesando {len(df_filtered)} cl√≠nicas con rating 4.0-4.5")

    scraper = GoogleMapsReviewsScraper(headless=True)

    all_reviews = []
    all_pain_points = {}
    all_pitches = []

    for idx, row in df_filtered.iterrows():
        place_name = row['name']

        # Extraer rese√±as
        reviews = scraper.extract_reviews_from_place(
            place_name=place_name,
            max_reviews=max_reviews_per_place
        )

        if reviews:
            all_reviews.extend(reviews)

            # Analizar pain points
            pain_points = scraper.analyze_pain_points(reviews)
            all_pain_points[place_name] = pain_points

            # Generar sugerencias de pitch
            pitches = scraper.generate_pitch_suggestions(pain_points)
            if pitches:
                all_pitches.append({
                    'place_name': place_name,
                    'rating': row['rating'],
                    'reviews_count': row.get('reviews_count', 0),
                    'phone': row.get('phone', ''),
                    'pitches': pitches
                })

        time.sleep(5)  # Pausa entre lugares

    # Guardar resultados
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    if all_reviews:
        scraper.save_to_excel(all_reviews, f'reviews_extraidas_{timestamp}.xlsx')

    if all_pain_points:
        scraper.save_to_json(all_pain_points, f'pain_points_{timestamp}.json')

    if all_pitches:
        df_pitches = pd.DataFrame(all_pitches)
        df_pitches.to_excel(f'pitch_suggestions_{timestamp}.xlsx', index=False)
        print(f"üíæ Sugerencias de pitch guardadas en: pitch_suggestions_{timestamp}.xlsx")

    scraper.close()

    return all_reviews, all_pain_points, all_pitches


if __name__ == "__main__":
    # Ejemplo de uso
    print("="*70)
    print("ü§ñ Google Maps Reviews Scraper")
    print("="*70)

    # Opci√≥n 1: Extraer rese√±as de un solo lugar
    scraper = GoogleMapsReviewsScraper(headless=False)

    place_name = "Cl√≠nica Odontol√≥gica Medell√≠n"  # Cambia por el nombre que quieras
    reviews = scraper.extract_reviews_from_place(place_name, max_reviews=20)

    if reviews:
        # Analizar pain points
        pain_points = scraper.analyze_pain_points(reviews)

        # Generar sugerencias de pitch
        pitches = scraper.generate_pitch_suggestions(pain_points)

        print(f"\n{'='*70}")
        print("üí° SUGERENCIAS DE PITCH")
        print(f"{'='*70}\n")
        for pitch in pitches:
            print(f"üìå {pitch['pain_point']} ({pitch['mentions']} menciones):")
            print(f"   {pitch['suggested_pitch']}\n")

        # Guardar
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        scraper.save_to_excel(reviews, f'reviews_{timestamp}.xlsx')
        scraper.save_to_json({'pain_points': pain_points, 'pitches': pitches}, f'analysis_{timestamp}.json')

    scraper.close()
